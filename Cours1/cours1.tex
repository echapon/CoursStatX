\documentclass[9pt]{beamer}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}
% \usepackage{beamerthemeplain}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{fontenc}
% \usepackage{verbatim}
\usepackage{graphics}
 
\usepackage{textcomp}
\usepackage[absolute,overlay]{textpos}

\usepackage{wasysym}

\usepackage{slashed}
\usepackage{array}

\usetheme{CNRScolors}

\input{../newcommands.tex}
\input{../custom-definitions.tex}

\graphicspath{ {../figures/}{./} }

\setbeamertemplate{navigation symbols}{}

 \newcolumntype{x}[1]{%
>{\centering\hspace{0pt}}p{#1}}%
\newcommand{\tn}{\tabularnewline}

\date[Stat1]{Sept. 20, 2018}
\title{Methods of statistical analysis and simulation}
\subtitle{Cours 1}
\author[E. Chapon]{Émilien Chapon}
% \institute[(CERN)]{CERN}
% \logo{\includegraphics[height=0.6cm]{../../CMS-Color-Label.pdf}\hspace{1.05\textwidth}\includegraphics[height=0.6cm]
% {../../LogoBadge.pdf} }

\begin{document}

{
\setbeamertemplate{footline}{}
\setbeamertemplate{headline}{}
% \logo{\includegraphics[height=1.2cm]{../../CMS-Color-Label.pdf}
% \hspace{0.94\textwidth}\includegraphics[height=1.2cm]{../../LogoBadge.pdf}}

\begin{frame}
 \maketitle
 
%  \setcounter{framenumber}{0}
\end{frame}
}

\begin{frame}
 \frametitle{Organisation of the class}
 
 \begin{block}{Organisation of the class}
  Two modules:
  
  \begin{itemize}
   \item Part 1: Methods of statistical analysis and simulation
   \begin{itemize}
    \item Émilien Chapon, $8\times 4$ hours
   \end{itemize}
   \item Part 2: Experiments and detector physics
   \begin{itemize}
    \item Jean-Claude Brient, $8\times 4$ hours
   \end{itemize}
  \end{itemize}

 \end{block}
 
 Exam for Methods of statistical analysis and simulation: TBD (likely article discussion)

\end{frame}

\section*{Introduction}

\begin{frame}
 \frametitle{Who am I?}
 
 \begin{itemize}
  \item Particle physicist at CERN
  \item CMS (general-purpose experiment at the CERN LHC)
  \item Studying heavy-ion collisions
  \item Graduated on the search for H$\to$WW at the Tevatron (D0)
 \end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Contents of this course}
 
 \begin{itemize}
  \item Probability and random variables
  \item Parameter estimation
  \item Hypothesis testing
 \end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Introduction}
 
 Introduction
\end{frame}

\begin{frame}
 \frametitle{Definitions are important}

 % Cousins slides, part 1 s5
 As in physics, much confusion can be avoided by being
precise about definitions, and much confusion can be
generated by being imprecise, or by assuming every-day
definitions in a technical context.

\begin{exampleblock}{Example}
 When you read: ``The confidence level tells you how much confidence one
has that the true value is in the confidence interval.''

$\to$ confusion on the ``usual'' and ``statistician'' meanings of the word confidence...

\end{exampleblock}

\end{frame}


\begin{frame}
 \frametitle{Language}
 
 \begin{center}
 \begin{tabular}{ll}
  Physicists say... & when Statisticians say... \\
  \hline
  Determine & Estimate \\
  Estimate & Guess \\
  Gaussian & Normal \\
  Breit-Wigner\footnote{This is what HEP physicists say. Others say Lorentzian...} & Cauchy \\
 \end{tabular}
 \end{center}
 
 (Side note: statistics is a field of mathematics, not a quantifier of data: avoid wishing for ``more statistics''...)
 

\end{frame}

\begin{frame}
 \frametitle{Key tasks in Statistics: important to distinguish!}
 
 \begin{description}
  \item<1->[Point estimation:] what single ``measured'' value of a parameter do you report?
  \item<2->[Interval estimation:] what interval (giving a measure of uncertainty of the parameter inference) do you report?
  \item<3->[Hypothesis testing:] Many special cases:
  \begin{enumerate}
   \item A given functional form (“model”) vs another functional
form. Also known as “model selection”.
  \item A single value of a parameter (say 0 or 1) vs all other values
  \item Goodness of Fit: A given functional form against all other
(unspecified) functional forms (aka “model checking”)
  \end{enumerate}
  \item<4>[Decision making:] What action should I take (tell no one, issue
press release, propose new experiment, ...) based on the
observed data? Rarely done formally in HEP, but important to
understand outline of formal theory, to avoid confusion with
inference and to inform informal application.
  \end{description}

\end{frame}

% \begin{frame}
%  \frametitle{Key tasks in Statistics: important to distinguish!}
%  
%  In frequentist statistics, the above hypothesis testing case,
%  
% \structure{(2) A single value of a parameter (say 0 or 1) vs all other values,}
% 
% maps identically onto interval estimation.
% 
% This is called the duality of “inversion of a hypothesis test to get
% confidence interval”, and vice versa, and will be discussed later.
% 
% In contrast, in Bayesian statistics, testing case (b) is an
% especially controversial form of case (a) model selection.
% The model with fixed value of parameter is lower-dimensional in
% parameter space than the model with parameter not fixed.
% 
% Again, I just mention this here to foreshadow a very deep issue,
% where frequentist and Bayesian methods do not converge in the
% limit of large data sets.
% 
% \end{frame}

\begin{frame}
 \frametitle{Two philosophies}
 
 Unfortunately, statisticians do not agree on basic principles. They can crudely be divided into two schools: Bayesian and frequentist (or classical). The name Bayesian
 derives from the extended use of Bayes theorem in the former group.
 
 \begin{block}{Bayesian}
  Closer to everyday reasoning, where probability is interpreted as a \emph{degree of belief} that something will happen, or that a parameter will have a given value. 
 \end{block}
 
 \begin{block}{Frequentist}
  Closer to scientific reasoning, where probability means the relative frenquency of something happening. This makes it more objective, since it can be determined independently of the 
  observer, but restricts its application to repeatable phenomena.
  
  In particular: one can define the frequentist probability for observing data (which are random), but not for the true value of a parameter (which is fixed, even if unknown).
 \end{block}


\end{frame}

\begin{frame}
 \frametitle{Frequentist vs Bayesian}
 
 In the areas of parameter estimation and hypothesis testing, numerical results tend to be the same with both approaches in the asymptotic regime (i.e. large data set).
 
 Differences do exist however (and can lead to ``paradoxes''):
 
 \begin{itemize}
  \item Exact frequentist results require as input the probabilities of observing all data, both the one actually measured and that which could have been observed (Monte-Carlo). This violates an important principle in Bayesian theory, and is not allwoed in the Bayesian method.
  \item Goodness-of-fit is essentially impossible to obtain in the Bayesian approach and is the traditional bastion of classical statistics.
  \item Exact Bayesian results require as input the prior beliefs of the physicist. This is necessarily subjective, and is not allowed with the frequentist method.
 \end{itemize}
 
 

\end{frame}


\begin{frame}[plain]
 \textbf{Today: probability and random variables}
\end{frame}

\begin{frame}[plain]
 \frametitle{Outline}
 
 \tableofcontents
\end{frame}

\section{Definitions}

\begin{frame}
 \frametitle{Random variable}
 
 \includegraphics[width=0.45\textwidth]{randomvar.pdf}\hfill
%  \includegraphics[width=0.32\textwidth]{randomvar2.pdf}\hfill
 \includegraphics[width=0.45\textwidth]{randomvar3.pdf}
 
 \begin{block}{Random variable: definition}
  A random variable is a variable whose possible values are outcomes of a random phenomenon. It usually denoted with a capital letter (e.g. $X$).
  
  The ensemble of the exclusive possible numerical values of $X$ is the sample space $\Omega$:
  
  $$\Omega = \left\{ x_1, x_2, \dots \right\}$$
 \end{block}
 
 Examples:
 
 \begin{itemize}
  \item $x$: \only<2>{lifetime of a particle? $\Omega = [0, +\infty [$}
%   \item $y$: \only<2>{measurement of the azimuthal angle?}
  \item $z$: \only<2>{tossing of a coin? (heads = 0, tails = 1) $\Omega = \{0,1\}$}
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Mathematical probability}
 
 \begin{block}{Definition}
  Given a random variable $X$ and a sample space $\Omega$, a function $P$ is a probability if it obeys the \textbf{Kolmogorov axioms}:
  
  \begin{enumerate}
   \item<1-> $\forall x \in \Omega, P(x) \geq 0$ (and $P(x) \in \mathbb{R})$
   \item<2-> $\forall A, B \subset \Omega / A \cap B = \emptyset, P(A \cup B) = P(A) + P(B) $
   \item<3-> $P(\Omega) = 1, P(\emptyset)=0$ 
  \end{enumerate}

 \end{block}
 
 \uncover<4>{
 In other words, in the discrete case $\Omega = \{ x_i \}$
 
 \begin{enumerate}
  \item $P(x_i \geq 0$ for all $i$
  \item $P(x_i \text{ or } x_j) = P(x_i) + P(x_j)$
  \item $\sum_\Omega P(x_i) = 1$
 \end{enumerate}
}

\end{frame}

\begin{frame}
 \frametitle{Frequentist probability}
 
 \begin{block}{Definition}
 Frequentist probability is defined in an empiric way. Given a random variable $X$ and a sample space $\Omega$, we repeat the experiment $N$ times and measure the outcome of $X$.
 
 For $A \subset \Omega$, and if we measure $n$ times $X \in A$, we then define 
 
 $$P(A) = \lim_{N \to \infty} \frac{n}{N}$$
\end{block}

\begin{itemize}
 \item Important implication: frequentist probability can only be applied to repeatable experiments. The frequentist probability that it rains tomorrow cannot be defined!
 \item In particular: $P(\text{constant of nature} \in \text{(some interval)})$ or $P(\text{SUSY is true})$ \alert{do not exist} (in a usueful way) for this definition of $P$ (at least in one universe).
\end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Bayesian probability}
 
 \begin{block}{definition}
  Bayesian probability is subjective and can be for instance defined using the \emph{degree of belief} (Finetti), with the notion of \emph{coherent bet}:
  
  $$P(A) = \frac{\text{money that you are ready to bet on measuring } X \in A}{\text{money that you stand to win}}$$
 \end{block}
 
 \begin{itemize}
  \item Bayesian is as much a property of the observer as of the system being observed.
  \item It depends on the state of the observer's knowledge, and will in general change as the observer obtains more knowledge.
  \item $P(\text{constant of nature} \in \text{(some interval)})$ or $P(\text{SUSY is true})$ exist for you!
  \item Shown to be basis for coherent personal decision making.
 \end{itemize}


\end{frame}

\begin{frame}
 \frametitle{Properties of probabitilies}
 
 \begin{block}{Addition law}
  Given $A, B \subset \Omega$, 
  
  $$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$
 \end{block}
 
 \uncover<2->{\begin{block}{Conditional probability and independence}
 \begin{itemize}
  \item<2-> We define the conditional probability of $A$ given $B$ (i.e. of $x \in A$, given that already $x \in B$), written $P(A|B)$. Then:
  
  $$P(A \cup B) = P(A|B) P(B) = P(B|A) P(A)$$  
  
  \item<3> Sets $A$ and $B$ are said to be \emph{independent} if $$P(A|B) = P(A)$$ and equivalently $$P(A \cup B) = P(A) P(B)$$
 \end{itemize}
 \end{block}}


\end{frame}

\begin{frame}
 \frametitle{Graphical illustration and ``derivation'' of Bayes' Theorem}
 \vspace{-5pt}
 
 \includegraphics[width=\textwidth]{BayesTheorem.png}
 
 \begin{large}$$\alert{P(B|A) = \frac{P(A|B) P(B)}{P(A)}}$$                                              \end{large}
\end{frame}

\begin{frame}
 \frametitle{Bayesian interpretation}
 
 $A$ is theory, $B$ is experiment
 
 $$P(\text{theory} | \text{experiment}) = \frac{P(\text{experiment}|\text{theory}) P(\text{theory})}{P(\text{experiment})}$$
 
 \begin{itemize}
  \item $P(\text{theory} | \text{experiment})$ is called the \textbf{posterior probability}.
  \item $P(\text{theory})$ is called the \textbf{prior probability}.
 \end{itemize}

\end{frame}


\begin{frame}
 \frametitle{Example of Bayes' theorem using frequentist probability}
 
 A b-tagging method is developed and one measures:
 
 \begin{itemize}
  \item $P(\text{btag} | \text{b-jet})$, i.e., efficiency for tagging b’s
  \item $P(\text{btag} | \text{not a b-jet})$, i.e., efficiency for background
  \item $P(\text{no btag} | \text{b-jet}) = 1 - P(\text{btag} | \text{b-jet})$
  \item $P(\text{no btag} | \text{not a b-jet}) = 1 - P(\text{btag} | \text{not a b-jet})$
 \end{itemize}
 
 \vspace{10pt}
 
Question: Given a selection of jets tagged as b-jets, what
fraction of them is b-jets? I.e., what is $P(\text{b-jet} | \text{btag})$ ?

\vspace{10pt}

\uncover<2>{
Answer: Cannot be determined from the given information!

Need in addition: $P(\text{b-jet})$, the true fraction of all jets that are
b-jets. Then Bayes’ theorem inverts the conditionality:

$$P(\text{b-jet} | \text{btag}) \propto P(\text{btag} |\text{b-jet}) P(\text{b-jet})$$
}

\end{frame}
\begin{frame}
 \frametitle{Example of Bayes' theorem using frequentist probability}
 
 In HEP, as noted, $P(\text{btag} | \text{b-jet})$ is called the \emph{efficiency} for tagging b’s.
 
 Meanwhile $P(\text{b-jet} | \text{btag})$ is often called the \emph{purity} of a sample of b-tagged jets.
 
As this is a pretty ``easy'' distinction, it is helpful to keep it in mind when one encounters cases where it is perhaps tempting to make the logical error of equating $P(A|B)$ and $P(B|A)$.

\end{frame}

\begin{frame}
 \frametitle{Example  of Bayes' theorem using Bayesian probability}
 
 In a background-free experiment, a theorist uses a ``model'' to
predict a signal with Poisson mean of 3 events. From Poisson
formula we know:

\begin{itemize}
 \item $P(\text{0 events} | \text{model true}) = 3^0 e^{-3}/0! = 0.05$
 \item $P(\text{0 events} | \text{model false}) = 1.0$
 \item $P(>\text{0 events} | \text{model true}) = 0.95$
 \item $P(>\text{0 events} | \text{model false}) = 0.0$
\end{itemize}

The experiment is performed and \emph{zero events are observed}.

\vspace{10pt}

Question: Given the result of the expt, what is the probability that
the model is true? I.e., What is $P(\text{model true} | \text{0 events})$ ?

\vspace{10pt}

\uncover<2>{Answer: Cannot be determined from the given information!

Need in addition: $P(\text{model true})$, the degree of belief in the
model prior to the experiment. Then Bayes’ theorem inverts the
conditionality:

$$P(\text{model true} | \text{0 events}) \propto P(\text{0 events} | \text{model true}) P(\text{model true})$$

or in other words (using Bayes' theorem with $A = \text{0 events}$, $B = \text{model true}$):

$$P(\text{model true} | \text{0 events}) = \frac{0.05  P(\text{model true})}{1 - 0.95 P(\text{model true})}$$
}

\end{frame}

\begin{frame}
 \frametitle{Example  of Bayes' theorem using Bayesian probability}
 
 $$P(\text{model true} | \text{0 events}) = \frac{0.05  P(\text{model true})}{1 - 0.95 P(\text{model true})}$$
 
Limiting cases to lowest order in $\epsilon$, with $\epsilon \ll 1$:

\vspace{10pt}

Let ``model'' be the Standard Model of particle physics, prior $P(\text{model true}) = 1 - \epsilon$, then $P(\text{model true} | \text{0 events}) \approx 1 - 20\epsilon$

Still very high degree of belief! Tempting mistake: ``$P(\text{0 events} | \text{model true}) = 5\%$, and 0 events observed, means there is 5\% chance the S.M. is true'' (UGH!)

\vspace{10pt}

Let ``model'' be large extra dimensions, prior $P(\text{model true}) = \epsilon$, then $P(\text{model true} | \text{0 events}) \approx 0.05 \epsilon$

Low prior belief becomes even lower.

\vspace{10pt}

N.B. More realistic examples are of course more complex.

\end{frame}

\begin{frame}
 \frametitle{Note relative to decisions}
 
 Suppose that as a result of the previous experiment, your degree
of belief in the model is $P(\text{model true} | \text{0 events}) = 99\%$, and you
need to decide on an action (making a press release, or planning
next experiment), based on the model being true.
Question: What should you decide?

\vspace{10pt}

\uncover<2>{Answer: Cannot be determined from the given information!

\vspace{10pt}

Need in addition:
The \emph{utility} function (or its negative, the \emph{loss} function), which
quantifies the relative costs (to You) of

\begin{itemize}
 \item Type I error (declaring model false when it is true), and
 \item Type II error (not declaring model false when it is false).
\end{itemize}
}

\end{frame}

\begin{frame}
\frametitle{Note relative to decisions}

Thus, Your decision, requires two subjective inputs: Your prior
probabilities, and the relative costs to You of outcomes.
Statisticians often focus on decision-making.

In HEP, the tradition thus far is to communicate experimental
results (well) short of formal decision calculations.

It will become clear when we come to hypothesis testing: 

Frequentist (classical) ``hypothesis testing'' (especially with
conventions like 95\% C.L. or $5\sigma$ ) is not a complete theory of
decision-making!

It is important to keep this in mind, since the ``accept/reject''
language of classical hypothesis testing is too
simplistic for ``deciding'' in important situations.

\end{frame}


\begin{frame}
 \frametitle{Discrete random variables $X$}
 
 
  $X \in \Omega = \{ x_1, x_2, \dots, x_N \}$ (where $N \in \mathbb{N} \cup \{+\infty\}$)
  
  Then, if $p_i = P(x_i)$:
  
  \begin{itemize}
   \item $\forall i, p_i \in [0,1]$
   \item $\sum_{i=1}^N p_i = 1$
  \end{itemize}

 \end{frame}
 
 \begin{frame}
 \frametitle{Continuous random variables $X$}
 
 \begin{block}{Cumulative function}
  $X \in \Omega = [a,b]$ where $(a,b) \in (\mathbb{R} \cup \{-\infty,+\infty\})^2$
  
  The probability law is defined using a function $F(x_0) = P(x \leq x_0)$, called the \alert{cumulative function}.
 \end{block}
 
 The cumulative function is such that:
 
 \begin{itemize}
  \item $F(b) = 1$
  \item $F(a) = 0$
  \item $\forall x \in [a,b], \frac{\dd F}{\dd x}(x) \geq 0$
 \end{itemize}

 \begin{block}{Probability density function (pdf)}
  The probability density function is defined as:
  
  $$f(x) \dd x = F(x+\dd x) - F(x) = P(X \in [x, x+\dd x])$$
  
  or, in other words:
  
  $$f(x) = \frac{\dd F}{\dd x}(x)$$
 \end{block}



\end{frame}

\begin{frame}
 \frametitle{Multi-dimensional variable}
 
 Example: $X = (x,y,z)$. 
 Then $P(x \in [x_0, x_0 + \dd x], y \in [y_0, y_0 + \dd y], z \in [z_0, z_0 + \dd z]) = f(x_0,y_0,z_0) \dd x \dd y \dd z$ where $f$ is the pdf.
 
 \begin{block}{Definition: marginal pdf}
  $$f_X (x) = \int \dd y^\prime \dd z^\prime\, f(x,y^\prime,z^\prime)$$
  
  $f_X$ is a \textbf{projection} of $f$
 \end{block}
 
 \begin{block}{Definition: conditional pdf}
  $$f_C (x, y_0, z_0) = \frac{f(x,y_0,z_0)}{\int \dd x^\prime f(x^\prime, y_0, z_0)}$$
  
  $f_C$ is a \textbf{``section''} of $f$
 \end{block}

 \begin{block}{Definition: independent variables}
  Given two random variables $X$ and $Y$, \\
  $X$ and $Y$ are independent iff $f(x,y) = f_X(x) f_Y(y)$.
 \end{block}


 
\end{frame}

\begin{frame}
 \frametitle{Change of variable}
 
 Let $f(\vec{x})$ be a pdf and a change of variables $h: \vec{x} \mapsto \vec{y} = h(\vec{x})$, $[\vec{x}, \vec{x} + \dd\vec{x}] \to [\vec{y}, \vec{y} + \dd\vec{y}]$
 
 \vspace{10pt}
 
 \structure{What is the pdf of $\vec{y}$: $g(\vec{y})$?}
 
 \uncover<2>{\only<2>{
 \begin{block}{If $x$ and $y$ are scalars, and $h$ bijective}
  \begin{eqnarray}
   g(y) \dd y & = & f(x) \dd x \nonumber \\
   g(y) & = & f(x) \left| \frac{\dd x}{\dd y}\right| = \frac{f(x)}{|h^\prime (x)|} \nonumber \\
   \structure{g(y)} & \structure{=} & \structure{\frac{f(x)}{\left| \frac{\dd y}{\dd x} \right|}}   
  \end{eqnarray}
  
  NB: $g$ is not defined where $h^\prime(x) = 0$.

 \end{block}

 }}
 
 \only<3>{
 \begin{block}{If $x$ and $y$ are scalars, and $h$ bijective}
  Several $[x_i,x_i+\dd x]$ correspond to a given $[y,y+\dd y]$
  
  Then \structure{$$g(y) = \sum{i, h(x_i) = y} \frac{f(x_i)}{|h^\prime(x_i)|}$$}
 \end{block}
 
 Examples:
 
 \begin{itemize}
  \item $$y = h(x) = x^2\quad \longrightarrow \quad g(y) = \frac{f(\sqrt{y}) + f(-\sqrt{y})}{2\sqrt{y}}$$
  \item $$y = h(x) = |x|\quad \longrightarrow \quad g(y) = \frac{f(y) + f(-y)}{1}$$
 \end{itemize}


 }
 
 \only<4>{
 \begin{block}{Case of multiple dimensions and a bijective $h$}
  \structure{$$g(\vec{y}) = \frac{f(\vec{x})}{\left| \det \left( \frac{\partial \vec{h}}{\partial \vec{x}} \right) \right|}$$}
  
  The denominator is the jacobian of the transformation.
 \end{block}

 }
 
\end{frame}

\section{Properties of pdfs}

\begin{frame}
 \frametitle{Properties of pdfs}
 
 $$X,\qquad f(x),\qquad x \in \Omega$$
  
\end{frame}

\begin{frame}
 \frametitle{Properties of pdfs}
 
 \begin{block}{Expectation of a function, $g(X)$}
  
  $$E(g) = \int_\Omega g(X) f(X) \dd X$$
  
  {\footnotesize NB: in the discrete case, $\int \leftarrow \sum$, $f(x) \dd x \leftarrow p_i (x_i)$ }
 \end{block}
 
 \begin{block}{Mean $\mu$ ($= \bar{X} = \langle X \rangle$)}
 
  $$\mu = E(X) = \int X f(X) \dd X$$
 \end{block}
 
 \end{frame}

\begin{frame}
 \frametitle{Properties of pdfs}

 \begin{block}{Variance $V$, standard deviation $\sigma$}
  \begin{eqnarray}
   V = \sigma^2 & \equiv & E \left( (X-\mu)^2 \right) \nonumber\\
   & = & E \left( X^2 - 2 \mu X + \mu^2\right) \nonumber\\
   \structure{V} & \structure{=} & \structure{E\left( x^2 \right) - \mu^2} \nonumber
  \end{eqnarray}

 \end{block}

 NB: not always defined (e.g. for the Breit-Wigner, aka Cauchy, distribution: undefined mean, infinite variance).

\end{frame}

\begin{frame}
 \frametitle{Moments}
 
 \begin{block}{Definition}
  \begin{itemize}
   \item Central moment: $E\left[ (X-\mu)^n \right]$
   \item Algebaric moment: $E\left[ X^n \right]$
  \end{itemize}

 \end{block}

 Particular cases: 
 
 \begin{itemize}
  \item $n=3$ central moment: \structure{skewness}. Measures the left-right asymmetry of the pdf.
  \item $n=4$ central moment: \structure{kurtosis}. Measures the size of the tails of the distribution (if positive, then larger tails than a Gaussian).
 \end{itemize}

 
\end{frame}

\begin{frame}
 \frametitle{Characteristic function of a pdf}
 
 \begin{block}{Definition}
  \begin{eqnarray}
   \Phi_X (t) & \equiv & E(e^{itx}) \qquad t \in \mathbb{R} \nonumber \\
   & = & \int_\Omega e^{itx} f(x) \dd x \qquad \text{(continuous)}\nonumber \\
   & = & \sum_k p_k e^{i t x_k}\qquad \text{(discrete)} \nonumber 
  \end{eqnarray}

 \end{block}
 
 If the pdf is continuous, then 
 $$f(x) = \frac{1}{2 \pi} \int_{-\infty}^{+\infty} \Phi_X(t) e^{-itx} \dd t$$
 
 Properties: $\Phi_X (0) = 0$, $|\Phi_X(t)| \leq 1 \quad \forall t$
 
 For $X,Y$ two independent variables: $\Phi_{X+Y}(t) = \Phi_X(t) \Phi_Y(t)$


\end{frame}

\begin{frame}
 \frametitle{Taylor development of the characteristic function}
 
 \begin{block}{}
  $$\Phi_X(t) = E(e^{itX}) = E \left( \sum_{n=0}^{+\infty} \frac{(itX)^p}{n!} \right) = \sum_{n=0}^{+\infty} \frac{(it)^n}{n!} E(X^n) $$
  
  where $E(X^n)$ is the $n$\ith moment
 \end{block}
 
 % I skip here a discussion from the ED class

\end{frame}

\begin{frame}
 \frametitle{Case of several variables}
 
 \begin{block}{Covariance $C(X,Y)$}
  $$C(X,Y) \equiv E \left( (X-\mu_X) (Y-\mu_Y) \right) = E(XY) - E(X) E(Y)$$
 \end{block}
 
 \begin{block}{Correlation coeffcient (or Pearson coefficient)}
  $$\rho(X,Y) \equiv \frac{C(X,Y)}{\sigma_X \sigma_Y}$$
 \end{block}
 
 \begin{block}{Schwartz lemma}
  $|\rho(X,Y)| \leq 1$
 \end{block}

 Demo of the Schwartz lemma:
 
 $$\forall \alpha, V(\alpha X + Y) = \alpha^2 V(X) + V(Y) + 2 \alpha C(X,Y) \geq 0$$
 
 This quadratic form can have one solution at most, hence its determinant is $\leq 0$: 
 
 $$C(X,Y)^2 - V(X) V(Y) \leq 0 \quad \text{(QED)}$$ 


\end{frame}

\begin{frame}
 \frametitle{Covariance: special cases}
 
 \begin{block}{Independent variables}
  $$X,Y \text{ independent} \Rightarrow C(X,Y) =0, \rho(X,Y) = 0$$
  
  NB: the opposite is not true (can have $C(X,Y)=0$ but $X$ and $Y$ not independent).
 \end{block}
 
 \begin{columns}
  \begin{column}{0.27\textwidth}
   \includegraphics[width=\textwidth]{circle}

   \centering
   $\rho=0$,\\ not independent
  \end{column}
  \begin{column}{0.27\textwidth}
   \includegraphics[width=\textwidth]{uncor}
   
   \centering
   $\rho=0$,\\ independent
  \end{column}
  \begin{column}{0.27\textwidth}
   \includegraphics[width=\textwidth]{cor}
   
   \centering
   $\rho=1$,\\ complete correlation
  \end{column}
  \begin{column}{0.27\textwidth}
   \includegraphics[width=\textwidth]{anticor}
   
   \centering
   $\rho=-1$,\\ complete anti-correlation
  \end{column}
 \end{columns}


\end{frame}

\begin{frame}
 \frametitle{Covariance matrix}
 
 \begin{block}{}
  $$\vec{X} = (X_1, \dots, X_N)$$
  
  $$V_{\vec{X}} = \begin{pmatrix}
                   \sigma_1^2 & C(X_1,X_2) & \cdots & C(X_1,X_N) \\
                   C(X_1,X_2) & \sigma_2^2 & \cdots & C(X_2,X_N) \\
                   \vdots & \ddots & \ddots &  \vdots \\
                   \vdots & \ddots & \ddots &  \sigma_N^2
                   \end{pmatrix}
$$
 \end{block}
 
 \begin{block}{Properties}
  \begin{itemize}
   \item The covariance matrix is symmetric.
   \item All its eigen values are positive.
  \end{itemize}

 \end{block}

\end{frame}

\begin{frame}
 \frametitle{Covariance matrix: change of variables}
 
 \begin{block}{Linear change of variables $\vec{Z} = A \vec{X} + B$}
  $$V_{\vec{Z}} = A\, V_{\vec{X}}\, ^t A$$
 \end{block}
 
 \begin{block}{}
  $$E \left( \sum_{i=1}^{N} a_i X_i \right) = \sum_{i=1}^{N} a_i E(X_i)$$
  $$V \left( \sum_{i=1}^{N} a_i X_i \right) = \sum_{i=1}^{N} a_i V(X_i) + 2 \sum_{i=1}^{N-1} \sum_{j=i+1}^{N} a_i a_j C(X_i,X_j)$$
 \end{block}

 \begin{block}{Nonlinear change of variables $\vec{Y} = \vec{H} (\vec{X})$}
  There is no exact formula for $V_{\vec{Y}}$. However,
  
  $$V_{\vec{Y}} = D V_{\vec{X}} D^{-1}$$
  
  where $D$ is the matrix of the derivatives (which determinant is the Jacobian), evaluated in $\vec{X}_0 = E(\vec{X})$.
 \end{block}


\end{frame}

\begin{frame}
 \frametitle{Application: sample mean}
 
 
 
  Assume $N$ realisations of $X$ for $N$ independent trials. For each trial, we have a pdf $f(x)$ with mean $\mu$ and variance $\sigma^2$. 
  
  Define $\bar{X} = \frac{1}{N} \sum_{i=1}^{N} X_i$
  
  \begin{itemize}
   \item $E(\bar{X}) = \frac{1}{N} \sum_i E(X_i) = \frac{1}{N} N \mu = \mu$ 
   \item $V(\bar{X}) = \frac{\sigma^2}{N}$
  \end{itemize}
 

\end{frame}

\section{Discrete laws}

\begin{frame}
 \frametitle{Outline}
 
 \tableofcontents[current]
\end{frame}

\begin{frame}
 \frametitle{Binomial law}
\end{frame}



\end{document}

